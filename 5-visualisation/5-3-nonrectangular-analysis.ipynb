{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GESIS Fall Seminar in Computational Social Science 2022\n",
    "### Introduction to Computational Social Science with Python\n",
    "# Day 5-3: Analysis of Non-Rectangular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "* Network analysis with NetworkX\n",
    "* Text analysis with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network analysis with [NetworkX](https://networkx.org/documentation/stable/)\n",
    "* NetworkX is a Python package for network analysis.\n",
    "* We can use it to study social networks!\n",
    "    - Networks can be explicitly social, e.g., who is friends with who.\n",
    "    - We can also study networks created through social processes, e.g., hyperlink network on the WWW, retweet networks, citation networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network basics\n",
    "* **Graph**\n",
    "    - Mathematical term for a network.\n",
    "* **Node** (or **Vertex**)\n",
    "    - The 'points' or individuals in the network.\n",
    "* **Edge**\n",
    "    - The connections between nodes.\n",
    "* **Directed / Undirected**\n",
    "    - Edges can have a direction (e.g., @Dave2008 follows @BarackObama on Twitter), or not have a direction (e.g., Dustin and Steve are friends).\n",
    "* **Weighted / Unweighted**\n",
    "    - Edges can have an associated weight or be unweighted (e.g., if we study a network of emails within an organisation, we can choose to include the number of emails exchanged as the edge weight).\n",
    "    \n",
    "    \n",
    "![network_diagram](figs/network_diagram.svg \"network_diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We can manually create a network (graph)\n",
    "g = nx.Graph() # By default an unweighted, undirected graph\n",
    "\n",
    "g.add_nodes_from([\"Milena\", \"Patrick\", \"Julius\", \"Erica\", \"Helen\", \"Barack\"])\n",
    "print(g.nodes()) #¬†we have nodes, but no edges\n",
    "print(g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some edges\n",
    "edgelist = [(\"Milena\", \"Patrick\"),\n",
    "           (\"Patrick\", \"Julius\"),\n",
    "           (\"Erica\", \"Helen\"),\n",
    "           (\"Patrick\", \"Helen\"),\n",
    "           (\"Erica\", \"Milena\"),\n",
    "           (\"Erica\", \"Helen\")]\n",
    "\n",
    "g.add_edges_from(edgelist) # add edges in the edgelist to our network\n",
    "# (we could skip the add_nodes_from stage, but would miss Barack from the network)\n",
    "\n",
    "nx.draw(g, with_labels=True) # plot the network (this is just a matplotlib axes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can also import data\n",
    "# This is a school social network where students name who they are friends with\n",
    "# A directed edge goes from the naming to the named student\n",
    "\n",
    "dixon_g = nx.read_edgelist(\"data/dixon_edgelist.txt\", create_using=nx.DiGraph()) #¬†Read as a directed graph\n",
    "print(nx.info(dixon_g)) # get some info\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "nx.draw(dixon_g, node_size=20, width=.2) # draw the graph (custom node size and edge width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More information, like node labels and attributes can be imported if we use another file type\n",
    "#¬†Several different graph file types can be read by networkx (GraphML, Pajek, GML, JSON, Pickle...)\n",
    "\n",
    "dixon_g = nx.read_graphml('data/dixon_network.graphml') #¬†read the graphml file\n",
    "print(nx.info(dixon_g)) #¬†get some info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can look at the full list of nodes\n",
    "print(dixon_g.nodes(data=True))\n",
    "\n",
    "# or a specific node\n",
    "print(dixon_g.nodes()['n100'])\n",
    "\n",
    "# or an attribute for every node\n",
    "print(dixon_g.nodes(data='race'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality\n",
    "* Which are the most important nodes in the network?\n",
    "* How do we measure the importance of nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree is a count of how many edges a node has\n",
    "#¬†In-degree is a count of how many edges into a node there are (number that name the student as a friend)\n",
    "# Out-degree is a count of how many edges out from a node there are (number that the student names as a friend)\n",
    "\n",
    "deg = dixon_g.degree() #¬†get degree, indegree, outdegree \n",
    "indeg = dixon_g.in_degree()\n",
    "outdeg = dixon_g.out_degree()\n",
    "print(deg)\n",
    "\n",
    "plt.hist(dict(deg).values(), bins=20) #¬†plot distribution\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Degree')\n",
    "plt.title('Degree distribution of students at Dixon High')\n",
    "plt.show()\n",
    "\n",
    "print('Max degree =', max(dict(deg).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PageRank is a similar centrality measure\n",
    "# PageRank takes into account not just number of neighbours, but importance of neighbours too\n",
    "#¬†If popular people name you as their friend, you have higher PageRank centrality than if unpopular people name you\n",
    "\n",
    "pr = nx.pagerank(dixon_g) #¬†get PageRank of nodes\n",
    "\n",
    "plt.hist(pr.values(), bins=20) #¬†plot distribution\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('PageRank')\n",
    "plt.title('PageRank distribution of students at Dixon High')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the mean PageRank for white vs black students\n",
    "pr_w = [v for k, v in pr.items() if dixon_g.nodes(data='race')[k]=='W']\n",
    "pr_b = [v for k, v in pr.items() if dixon_g.nodes(data='race')[k]=='B']\n",
    "\n",
    "print('White student mean PageRank', sum(pr_w)/len(pr_w))\n",
    "print('Black student mean PageRank', sum(pr_b)/len(pr_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much more to networkx\n",
    "* Community detection, shortest paths, graph similarity, connectivity, k-core, ...\n",
    "* Other Python network packages: graph-tool, igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è PRACTICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Plot a scatter graph of indegree vs outdegree for students at Dixon High\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Print the mean PageRank centrality for students at Dixon High in each grade 7-12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis with [NLTK](https://www.nltk.org/)\n",
    "* Natural Language Tool Kit is a suite of libraries for Natural Language Processing (NLP) in Python.\n",
    "* NLTK can perform part of speech tagging, named entity recognition, sentiment analysis, word embeddings, etc...\n",
    "* Integrates well with many other NLP packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# nltk.download() #¬†NLTK relies on lots of datasets (popular texts, stopwords, languages), download all with this\n",
    "nltk.download(\"stopwords\") # \n",
    "\n",
    "# Read Biden speech\n",
    "with open('data/biden_inauguration_millercenter.txt', 'r') as f:\n",
    "    bidenspeech = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tokenize the speech, and remove punctuation, stopwords\n",
    "\n",
    "words = word_tokenize(bidenspeech) # tokenize the speech\n",
    "print(words[:20])\n",
    "words = [x for x in words if x.isalpha()] # remove words with punctuation\n",
    "print(words[:20])\n",
    "words = [x for x in words if x.lower() not in stopwords.words(\"english\")] # remove stopwords\n",
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also 'Stem' the words (extract the root word)\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And lemmatize the words (extract the root word, mapped to dictionary version, i.e., no chopped off ends)\n",
    "# Note that names are handled better here\n",
    "lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "print(lemmed[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count the number of words, how often they're used\n",
    "\n",
    "import pandas as pd\n",
    "wordcounts = pd.Series(lemmed).value_counts()\n",
    "wordcounts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è PRACTICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Repeat the tasks above in NLTK with the Trump speech (data/trump_inauguration_millercenter.txt)\n",
    "# Who used more unique words? Compare the top words used.\n",
    "# There are some mistakes/quirks to the stemmed & lemmed word lists, can you explain any of them?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
