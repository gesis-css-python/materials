{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GESIS Fall Seminar in Computational Social Science 2022\n",
    "### Introduction to Computational Social Science with Python\n",
    "# Day 3-1: Handling Social Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "* Ethics of data access\n",
    "* Reading and writing common file types\n",
    "* More complex data types: time, dates, Unicode, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics of data access\n",
    "* Ethics vs the law\n",
    "* T&Cs and robots.txt\n",
    "* Database dumps, APIs, Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethics vs the law\n",
    "* This does not constitute legal advice, you are responsible for your own computer use.\n",
    "* The international and often outdated nature of Internet law makes this murky territory.\n",
    "* It's best to provide identifying information so you can be contacted in case of issues.\n",
    "* Request data at a reasonable rate, and take only what you need.\n",
    "* Automated data collection may be easy, but remain respectful of public/private data, copyright, and institution ethics procedures.\n",
    "* Sometimes ethics and the site terms and conditions can be at odds with each other.\n",
    "* Terms and conditions might be scary, but are often [not legally enforcible](https://www.eff.org/deeplinks/2022/04/scraping-public-websites-still-isnt-crime-court-appeals-declares). Though you may still be blocked or restricted from site access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T&Cs and robots.txt\n",
    "* Policies for scraping and API use can typically be found in the website Terms & Conditions and the robots.txt file.\n",
    "* Be more respectful of smaller websites (maybe get in contact).\n",
    "* Be more wary of larger company websites (especially with large projects).\n",
    "     - That said, there are usually lots of github repos and blogs from people who have tried scraping these platforms. Learn from their experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database dumps, APIs, Scraping\n",
    "* Sometimes, websites make full/partial dumps of their data available. These are a useful first step to explore data.\n",
    "* As a next step, consider API usage. This is an official channel which can be controlled and monitored by the platform.\n",
    "* If neither of these are available or you need more data, turn to scraping (effectively simulating a user browsing the site)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è PRACTICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Find the policies on scraping data and API usage for a popular online platform. Write a short paragraph on what you find, considering the following questions:\n",
    "* What data collection is permitted? Under what conditions? How frequently?\n",
    "* How would the data acquired compare to what a typical user sees?\n",
    "* How would the data acquired compare to what the platform has access to?\n",
    "* Why are there discrepancies between the available data and what the user/platform can access?\n",
    "* Any other surprises?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing common file types\n",
    "* In order to read/write files we need to tell Python:\n",
    "    - Where the file is on our computer.\n",
    "    - How to read/write it.\n",
    "    - To open the file.\n",
    "    - What to read/write.\n",
    "    - To close the file.\n",
    "* The most common file types you will read/write are .txt, .csv, .json, and .pickle (and variants thereof)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the os module to get the current working directory\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# We can use 'relative' file paths from here to read files (see below)\n",
    "\n",
    "# If we want to read a file from outside this folder, we need to specify the full filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read/write a file\n",
    "We can open text files with several modes:\n",
    "* \"r\" ‚Äì read a file\n",
    "* \"r+\" ‚Äì read and write to a file\n",
    "* \"w\" ‚Äì write to a file (creates new file / overwrites existing content)\n",
    "* \"w+\" ‚Äì read and write to a file (creates new file / overwrites existing content)\n",
    "* \"a\" ‚Äì appending to an already existing file\n",
    "* \"a+\" ‚Äì append to a file after reading\n",
    "\n",
    "![fopen](figs/fopen.png \"fopen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File open/read/close syntax\n",
    "\n",
    "# Read full file as a string\n",
    "f = open('data/demo.txt', 'r')\n",
    "alltxt = f.read()\n",
    "f.close()\n",
    "\n",
    "# Read first line(s) as a string\n",
    "f = open('data/demo.txt', 'r')\n",
    "firstline = f.readline()\n",
    "secondline = f.readline()\n",
    "f.close()\n",
    "\n",
    "f = open('data/demo.txt', 'r')\n",
    "alllines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "print(alltxt)\n",
    "print()\n",
    "print(firstline)\n",
    "print(secondline)\n",
    "print()\n",
    "print(alllines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be easy to forget the f.close() command, so more common syntax is:\n",
    "\n",
    "# Reading\n",
    "with open('data/demo.txt','r') as f:\n",
    "    alllines = f.readlines()\n",
    "\n",
    "# This opens, reads, then automatically closes the file\n",
    "\n",
    "print(alllines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestowrite = ['first line\\n', 'second line\\n', '\\n', 'My name is: \\n']\n",
    "\n",
    "# Writing\n",
    "with open('myfirstfile.txt','w') as f:\n",
    "    f.writelines(linestowrite)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttoappend = 'Patrick Gildersleve\\n@pgildersleve'\n",
    "\n",
    "# Appending\n",
    "with open('myfirstfile.txt','a') as f:\n",
    "    f.write(texttoappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many files are text encoded and can be read/written in a similar way by the basic file read syntax. In practice there are often dedicated modules for more complex filetypes, but for demonstration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a .ipynb file\n",
    "with open('3-2-scraping-data.ipynb','r') as f:\n",
    "    ipynb = f.read()\n",
    "\n",
    "print(ipynb[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a .html file\n",
    "\n",
    "with open('data/PL_table.html','r') as f:\n",
    "    html = f.read()\n",
    "\n",
    "print(html[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "* Comma-Separated Values - A text file format where fields are separated by commas and rows by newlines.\n",
    "* Frequently used to store tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a .csv file\n",
    "\n",
    "with open('data/WTA_2016.csv','r') as f:\n",
    "    csvdata = f.read()\n",
    "\n",
    "print(csvdata[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually parse the csv data\n",
    "\n",
    "# split each line\n",
    "csvlines = csvdata.split('\\n')\n",
    "for l in csvlines[:5]:\n",
    "    print(l)\n",
    "\n",
    "# split at each comma\n",
    "csvtable = [x.split(',') for x in csvlines]\n",
    "for r in csvtable[:5]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, the csv module (and functions built into many other packages) handles all the reading and parsing:\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/WTA_2016.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    csvtable = [list(x) for x in reader]\n",
    " \n",
    "for r in csvtable[:5]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "* \"JavaScript Object Notation\" - an open file format used to store structured attribute/value pairs and arrays in a readable text format.\n",
    "* For Python, it is useful for storing structured data like dictionaries and lists.\n",
    "* Frequently encountered when using web APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fruit = {'banana':'yellow', 'orange':'orange', 'apple':['red', 'green']}\n",
    "\n",
    "with open('fruit.json', 'w') as f:\n",
    "    json.dump(fruit, f) # json.dump to write data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fruit.json', 'r') as f:\n",
    "    readfruit = json.load(f)  # json.load to read data\n",
    "    \n",
    "print(readfruit)\n",
    "print(type(readfruit)) # automatically reads as a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary files\n",
    "We can also read/write binary encoded files, such as 'pickle' files. These are useful for storing Python objects. In this case, Python does not try to convert the bytes it reads to string characters (because they're not string characters), and lets the module do the decoding.\n",
    "\n",
    "We can open binary files with several modes:\n",
    "* \"rb\" ‚Äì read a file\n",
    "* \"rb+\" ‚Äì read and write to a file\n",
    "* \"wb\" ‚Äì write to a file (creates new file / overwrites existing content)\n",
    "* \"wb+\" ‚Äì read and write to a file (creates new file / overwrites existing content)\n",
    "* \"ab\" ‚Äì appending to an already existing file\n",
    "* \"ab+\" ‚Äì append to a file after reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fruit = {'banana':'yellow', 'orange':'orange', 'apple':['red', 'green']}\n",
    "\n",
    "# Write the file using pickle \n",
    "with open('fruit.pickle', 'wb') as f:\n",
    "    pickle.dump(fruit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using pickle \n",
    "with open('fruit.pickle', 'rb') as f:\n",
    "    readfruit = pickle.load(f)\n",
    "    \n",
    "print(readfruit)\n",
    "print(type(readfruit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`glob`](https://docs.python.org/3/library/glob.html) is a useful module for bulk selecting files to be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# '*' acts as a wildcard so you can find all files that match a pattern\n",
    "filelist = glob.glob('data/WTA_*.csv')\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files in the filelist\n",
    "\n",
    "alltext = ''\n",
    "for filename in sorted(filelist):\n",
    "    with open(filename, 'r') as f:\n",
    "        header = f.readline() # reads the header\n",
    "        text = f.read() # starts reading after the header\n",
    "        alltext += text\n",
    "        \n",
    "print(alltext[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è PRACTICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: Create a dictionary with keys 0-10, each element should be a list of the keys raised to powers 0-10\n",
    "# e.g. 2:[1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "# Save this dictionary to a pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Read the pickle file you just created. Add items (keys + power list) for the keys 11-20 to the dict.\n",
    "# Save the result as a json file and use your file browser to check you can view it in a text editor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Write a program which takes a student register and saves it as register.txt\n",
    "# The first line should just be \"Name\", and written immediately upon file creation.\n",
    "# Subsequent lines should take user input, and append the inputted name to the file.\n",
    "# Remember to add a mechanism to stop inputting names\n",
    "# The program should make use of both the 'w+' file mode (when creating the file),\n",
    "#¬†and the 'a' file mode (when appending names).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex data types: time, dates, Unicode, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen basic data types in Python such as `int`, `float`, `str`, etc... There are several other modules with associated data types that are frequently used in Computational Social Science in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "* The 'Epoch', when computer time starts, is on January 1st, 1970, 00:00 UTC.\n",
    "* Computers measure time by the number of seconds since this date.\n",
    "* We can use the `time` module to measure the time, pause code, \n",
    "* Not covered here, but time and date can get complex very quickly: timezones, leap years, leap seconds, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timenow = time.time()\n",
    "print('It has been %f seconds since January 1st, 1970, 00:00 UTC' %timenow)\n",
    "print('It has been %f years since January 1st, 1970, 00:00 UTC' %(timenow/(60*60*24*365)))\n",
    "\n",
    "print('The time is: ' + time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use time.sleep(x) to pause for x seconds (useful when rate limiting when scraping)\n",
    "for i in range(5,0,-1):\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "print('Liftoff!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit is an IPython magic function that allows you to time lines of code\n",
    "# Use it to help test your code and make it faster!\n",
    "\n",
    "letters = ['a', 'b', 'c', 'd']\n",
    "%timeit ' '.join(letters)\n",
    "%timeit '%s %s %s %s' %(letters[0], letters[1], letters[2], letters[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime\n",
    "* `datetime` is more capable and user friendly than `time` when handling dates.\n",
    "* 5 important classes:\n",
    "   - `datetime` ‚Äì Handles times and dates together (month, day, year, hour, second, microsecond).\n",
    "   - `date` ‚Äì Handles dates independent of time (month, day, year).\n",
    "   - `time` ‚Äì Handles time independent of date (hour, minute, second, microsecond).\n",
    "   - `timedelta` ‚Äî Durations of and differences in datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# We can create datetime objects\n",
    "date0 = datetime.datetime.now()\n",
    "print(date0)\n",
    "\n",
    "date1 = datetime.datetime(2022, 4, 1, 12, 32, 54)\n",
    "print(date1)\n",
    "\n",
    "date2 = datetime.date(2016, 6, 26)\n",
    "print(date2)\n",
    "\n",
    "date3 = datetime.time(2, 24, 13)\n",
    "print(date3)\n",
    "\n",
    "date4 = datetime.timedelta(days=50, minutes=50)\n",
    "print(date4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract values from datetime objects\n",
    "print(date0.year)\n",
    "print(date1.month)\n",
    "print(date2.day)\n",
    "print(date3.hour)\n",
    "\n",
    "print(date4.total_seconds()) # timedelta behaves slightly differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also perform basic date arithmetic\n",
    "\n",
    "# Get timedelta between datetimes\n",
    "print(date0 - date1)\n",
    "\n",
    "# Add/subtract timedelta to/from datetime\n",
    "print(date0 + date4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom extraction/printing of datetimes is done with strptime / strftime functions:\n",
    "# https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n",
    "# Datetimes can be read/printed with specific format codes\n",
    "\n",
    "xmas_string = '25 December 2022'\n",
    "xmas_datetime = datetime.datetime.strptime(xmas_string, '%d %B %Y')\n",
    "print(xmas_datetime)\n",
    "\n",
    "date0 = datetime.datetime.now()\n",
    "date0_string = datetime.datetime.strftime(date0, '%d/%m/%Y')\n",
    "print(date0_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unicode\n",
    "* Computers need to handle a wide array of characters: Latin alphabet, punctuation, accents, Chinese characters, emoji...\n",
    "* Historically, not all of these have been supported. There are even competing/conflicting standards.\n",
    "* An 'encoding' determines how a computer translates the bytes it reads into the character you see.\n",
    "* \"**Unicode**\" is a standard format for consistent encoding, representation, and handling of text.\n",
    "    - Several different Unicode encodings exist.\n",
    "* Default encoding in Python, and many other places, is **UTF-8**: \"Unicode Transformation Format ‚Äì 8-bit\"\n",
    "    - Other unicode and non-unicode encodings exist.\n",
    "* Any string you see within Python is Unicode (and almost always UTF-8).\n",
    "* Sometimes (older) files, particularly across different languages, are encoded differently.\n",
    "    - There is no foolproof way of detecting encoding!\n",
    "    - Sometimes you have to rely on domain knowledge, and manual inspection to decode files.\n",
    "    - Pray that you don't have to worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can convert the character strings we see to \"bytestrings\" for a particular encoding\n",
    "\n",
    "s = 'GuÃàrzenichstra√üe'\n",
    "\n",
    "# The output is an ASCII representation (i.e. simple characters only) of the bytestring\n",
    "print(s.encode('utf-8'))\n",
    "print(s.encode('utf-16'))\n",
    "\n",
    "# Encoding in one encoding, then decoding in another encoding often raises an error\n",
    "\n",
    "try:\n",
    "    print(s.encode('utf-16').decode('utf-8'))\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "# Though not always...\n",
    "\n",
    "try:\n",
    "    print(s.encode('utf-8').decode('utf-16'))\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    \n",
    "# This is why detecting encoding can be difficult!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try read a file 'encodings.txt'\n",
    "\n",
    "# with open('data/encodings.txt', 'r') as f:\n",
    "#     s = f.read()\n",
    "    \n",
    "# This fails, as the file is not encoded in utf-8 (or rather, utf-8 cannot decode it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know that the file was encoded with the Chinese 'gb18030' format\n",
    "# So we can specify that when reading the file\n",
    "\n",
    "with open('data/encodings.txt', 'r', encoding='gb18030') as f:\n",
    "    s = f.read()\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't know the encoding, we can try use the chardet package to guess it\n",
    "import chardet\n",
    "\n",
    "with open('data/encodings.txt', 'rb') as f: #¬†read *binary*\n",
    "    s = f.read()\n",
    "    \n",
    "print(chardet.detect(s))\n",
    "print(s.decode(chardet.detect(s)['encoding']))\n",
    "# Well, it decoded the file, but not as we hoped..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within an encoding, there are sometimes different ways of representing a character\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "s1 = 'G√ºrzenichstra√üe'\n",
    "s2 = 'GuÃàrzenichstra√üe'\n",
    "\n",
    "print(s1, s2, s1==s2)\n",
    "print()\n",
    "# Visually, these strings look the same, but they are not returning True when compared\n",
    "# They have the same unicode encoding, so what is happening?\n",
    "\n",
    "# Let's look at the bytestrings\n",
    "print(s1.encode())\n",
    "print(s2.encode())\n",
    "print()\n",
    "\n",
    "# The accented character is encoded in two different ways (effectively 2 different characters)\n",
    "# We need to Normalize the strings\n",
    "\n",
    "n1 = unicodedata.normalize('NFD', s1)\n",
    "n2 = unicodedata.normalize('NFD', s2)\n",
    "print(n1, n2, n1==n2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "* NumPy is a widely used Python library for handling multidimensional arrays and performing efficient mathematical operations on them.\n",
    "* Core object is the ndarray.\n",
    "* Used under-the-hood of many other popular packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create 1 dimensional arrays:\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "print(x, y, x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 dimensional arrays:\n",
    "\n",
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = np.array([[1, 2, 0], [8, 3, 4]])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access array elements with familiar index operations:\n",
    "\n",
    "print(x[0, 1])\n",
    "print(x[0])\n",
    "print(x[:, 1])\n",
    "print(x[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly create arrays:\n",
    "\n",
    "print(np.zeros(10))\n",
    "print(np.ones(15))\n",
    "print(np.arange(0, 10, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of, and reshape arrays:\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print()\n",
    "print(x.reshape(6)) # a 1D array\n",
    "print(x.reshape(1, 6)) # a 2D array with shape 1, 6\n",
    "print(x.reshape(6, 1)) # a 2D array with shape 6, 1\n",
    "print(x.reshape(3, 2)) # a 2D array with shape 3, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è PRACTICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Read the file \"mystery.txt\" and print the character string output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Read the file 'randomarray.txt' into numpy. \n",
    "# Use numpy to take the logarithm of all elements.\n",
    "# Reshape the array from (x, y) to (y, x) shape\n",
    "# Write the array to a new file 'log_randomarray_T.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: Read all the WTA_*.csv files and join them together (without using the csv module).\n",
    "# Parse the data such that each line is a list, and each element is the correct type (str/int/datetime/etc.)\n",
    "# Each line: []\n",
    "# Save the final object as a pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: Choose a World Bank indicator from https://data.worldbank.org/indicator\n",
    "# Download the data and read the file(s) as appropriate data structures in Python\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
